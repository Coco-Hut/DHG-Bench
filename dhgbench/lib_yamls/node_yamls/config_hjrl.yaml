default:
  All_num_layers: 2
  embedding_hidden: 128
  MLP_hidden: 128
  epochs: 100
  dropout: 0.5
  lr: 1.0e-3
  wd: 0

  activation: "relu"
  neg_slope: 0.01

  gamma: 0.1 
  sample_ratio: 0.1 
  weight_init: 1  
  pos_weight_thresh: 1.0e4 

cora:
  All_num_layers: 2
  embedding_hidden: 128
  MLP_hidden: 256
  epochs: 100
  dropout: 0.5
  lr: 1.0e-3
  wd: 0

  activation: "relu"
  neg_slope: 0.01

  gamma: 0.01 
  sample_ratio: false 
  weight_init: 1  
  pos_weight_thresh: 1.0e4 

