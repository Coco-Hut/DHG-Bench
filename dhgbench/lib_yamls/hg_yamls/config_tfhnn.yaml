default:
  All_num_layers: 2
  embedding_hidden: 128
  MLP_hidden: 128
  MLP_num_layers: 2
  epochs: 100
  dropout: 0.5
  alpha: 0.5
  lr: 1.0e-3 
  wd: 0.0
  normalization: "ln"

RHG_10:
  All_num_layers: 1
  embedding_hidden: 64
  MLP_hidden: 64
  MLP_num_layers: 2
  epochs: 200
  dropout: 0.2
  alpha: 0.1
  lr: 1.0e-2 
  wd: 0.0
  normalization: "ln"

  pooling: "mean"
  early_stop: true
  hg_batch_size: 128

